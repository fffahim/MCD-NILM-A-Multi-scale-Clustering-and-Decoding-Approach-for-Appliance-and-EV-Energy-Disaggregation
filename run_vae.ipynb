{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%run data_preprocess.ipynb\n",
    "%run helper.ipynb\n",
    "%run wrapper.ipynb\n",
    "%run models/vae.ipynb\n",
    "%run visualize.ipynb\n",
    "%run data_postprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = PrepareDataForQuantile()\n",
    "customStopper = CustomStopper()\n",
    "visualizer = Visualizer()\n",
    "post_process = DataPostProcess()\n",
    "wrapper = Wrapper()\n",
    "model_evaluation = ModelEvaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file\n",
    "with open(\"Config/model_config.json\") as data_file:\n",
    "    model_param = json.load(data_file)\n",
    "    model_param = model_param[\"vae\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrigerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param[\"training\"][\"batch_size\"] = model_param[\"training\"][\"batch_sizes\"][0]\n",
    "model_param[\"preprocessing\"][\"width\"] = model_param[\"preprocessing\"][\"widths\"][0]\n",
    "model_param[\"preprocessing\"][\"strides\"] = model_param[\"preprocessing\"][\"strides_list\"][0]\n",
    "model_param[\"appliance\"] = model_param[\"appliances\"][0]\n",
    "\n",
    "main_mean = model_param[\"preprocessing\"][\"main_mean\"]\n",
    "main_std = model_param[\"preprocessing\"][\"main_std\"]\n",
    "\n",
    "app_mean = model_param[\"preprocessing\"][\"app_mean\"]\n",
    "app_std = model_param[\"preprocessing\"][\"app_std\"]\n",
    "\n",
    "# main_mean = 1482.27\n",
    "# main_std = 1317.26\n",
    "\n",
    "# app_mean = 204.14\n",
    "# app_std = 737.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = helper.get_data_for_vae(0, 1, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = model_param[\"training\"][\"epoch\"]\n",
    "batch_size = model_param[\"training\"][\"batch_size\"]\n",
    "\n",
    "STEPS_PER_EPOCH = x_train.shape[0]//batch_size\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "                float(model_param[\"training\"][\"lr\"]), \n",
    "                decay_steps=STEPS_PER_EPOCH*model_param[\"training\"][\"decay_steps\"],\n",
    "                decay_rate=1,\n",
    "                staircase=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(model_param[\"model\"], model_param[\"config\"], model_param[\"preprocessing\"][\"width\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_callbacks = []\n",
    "patience = model_param[\"training\"][\"patience\"]\n",
    "start_epoch = model_param[\"training\"][\"start_stopping\"]\n",
    "\n",
    "print(\"Patience : {}, Start at : {}\".format(patience, start_epoch))\n",
    "\n",
    "es_callback = CustomStopper(monitor='val_loss', patience=patience, start_epoch=start_epoch, mode=\"auto\")\n",
    "\n",
    "list_callbacks.append(es_callback)\n",
    "\n",
    "eps_train = np.random.normal(size=(x_train.shape[0], 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.config.experimental.reset_memory_stats('GPU:0')\n",
    "\n",
    "history = model.fit((x_train-main_mean)/main_std, (y_train-app_mean)/app_std, validation_split=model_param[\"training\"][\"validation_split\"], shuffle=True, \n",
    "                                epochs=epochs, batch_size=batch_size, callbacks=list_callbacks, verbose=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "print(\"üîÅ TF training memory (peak):\", mem_info['peak'] / (1024 ** 2), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model\n",
    "import psutil\n",
    "import os\n",
    "process = psutil.Process(os.getpid())\n",
    "mem_before = process.memory_info().rss\n",
    "# eps_test = np.random.normal(size=(x_test.shape[0], 16))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "mem_after = process.memory_info().rss\n",
    "print(\"üß† TF inference memory (CPU):\", (mem_after - mem_before) / (1024 ** 2), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os\n",
    "dummy_input = np.random.normal(size=(2592, model_param[\"preprocessing\"][\"width\"], 1))\n",
    "process = psutil.Process(os.getpid())\n",
    "mem_before = process.memory_info().rss\n",
    "print(\"Dummy input shape:\", dummy_input.shape)\n",
    "model.predict(dummy_input)\n",
    "\n",
    "mem_after = process.memory_info().rss\n",
    "print(\"Inference memory used (MB):\", (mem_after - mem_before) / (1024 ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = y_pred.reshape([1, -1])\n",
    "# y_test = y_test.reshape([1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred.min(), y_pred.max(), y_test.min(), y_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_pred = reconstruct(y_pred[:]*app_std+app_mean, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "x_all = reconstruct(x_test[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "y_all_true = reconstruct(y_test[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_pred.shape, x_all.shape, y_all_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the nan values\n",
    "y_all_pred = y_all_pred[~np.isnan(y_all_pred)]\n",
    "y_all_true = y_all_true[~np.isnan(y_all_true)]\n",
    "x_all = x_all[~np.isnan(x_all)]\n",
    "# sum of nan values in the array\n",
    "np.isnan(y_all_pred).sum(), np.isnan(y_all_true).sum(), np.isnan(x_all).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_pred.shape, x_all.shape, y_all_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total, y_total_pred, y_total_true = post_process.post_process_vae(x_all, y_all_pred, y_all_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total_pred_refrigerator = y_total_pred\n",
    "y_total_true_refrigerator = y_total_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total_pred_refrigerator[0, :].shape, y_total_true_refrigerator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a dataframe with the true and predicted values\n",
    "import pandas as pd\n",
    "output_data = pd.DataFrame({\n",
    "    'y_total_pred': y_total_pred_refrigerator[0, :],\n",
    "    'y_total_true': y_total_true_refrigerator[0, :]\n",
    "})\n",
    "\n",
    "output_data.to_csv(\"Results/output/vae_refrigerator_8156_withoutev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = pd.read_csv(\"Results/output/vae_refrigerator_661_withoutev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total_pred2 = data_temp['y_total_pred'].values\n",
    "y_total_true2 = data_temp['y_total_true'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20,10))\n",
    "plt.plot(y_total_true[0, :200], label=\"True\")\n",
    "plt.plot(y_total_pred[0, :200], label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true[0, :], y_total_pred[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true[0, :], y_total_pred[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the same code for clotheswasher1\n",
    "model_param[\"training\"][\"batch_size\"] = model_param[\"training\"][\"batch_sizes\"][1]\n",
    "model_param[\"preprocessing\"][\"width\"] = model_param[\"preprocessing\"][\"widths\"][1]\n",
    "model_param[\"preprocessing\"][\"strides\"] = model_param[\"preprocessing\"][\"strides_list\"][1]\n",
    "model_param[\"appliance\"] = model_param[\"appliances\"][1]\n",
    "\n",
    "main_mean = model_param[\"preprocessing\"][\"main_mean\"]\n",
    "main_std = model_param[\"preprocessing\"][\"main_std\"]\n",
    "\n",
    "app_mean = model_param[\"preprocessing\"][\"app_mean\"]\n",
    "app_std = model_param[\"preprocessing\"][\"app_std\"]\n",
    "\n",
    "x_train_wm, y_train_wm, x_test_wm, y_test_wm = helper.get_data_for_vae(1, 2, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = model_param[\"training\"][\"epoch\"]\n",
    "batch_size = model_param[\"training\"][\"batch_size\"]\n",
    "\n",
    "STEPS_PER_EPOCH = x_train.shape[0]//batch_size\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "                float(model_param[\"training\"][\"lr\"]), \n",
    "                decay_steps=STEPS_PER_EPOCH*model_param[\"training\"][\"decay_steps\"],\n",
    "                decay_rate=1,\n",
    "                staircase=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(lr_schedule)\n",
    "\n",
    "model_ev = create_model(model_param[\"model\"], model_param[\"config\"], model_param[\"preprocessing\"][\"width\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_callbacks = []\n",
    "patience = model_param[\"training\"][\"patience\"]\n",
    "start_epoch = model_param[\"training\"][\"start_stopping\"]\n",
    "\n",
    "print(\"Patience : {}, Start at : {}\".format(patience, start_epoch))\n",
    "\n",
    "es_callback = CustomStopper(monitor='val_loss', patience=patience, start_epoch=start_epoch, mode=\"auto\")\n",
    "\n",
    "list_callbacks.append(es_callback)\n",
    "\n",
    "history_ev = model_ev.fit((x_train_wm-main_mean)/main_std, (y_train_wm-app_mean)/app_std, validation_split=model_param[\"training\"][\"validation_split\"], shuffle=True,\n",
    "                                epochs=epochs, batch_size=batch_size, callbacks=list_callbacks, verbose=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test the model\n",
    "y_pred_ev = model_ev.predict((x_test_wm-main_mean)/main_std, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_wm = y_pred_ev.reshape([1, -1])\n",
    "y_test_wm = y_test_wm.reshape([1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_all_pred_ev = reconstruct(y_pred_ev[:]*app_std+app_mean, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "x_all_ev = reconstruct(x_test_wm[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "y_all_true_ev = reconstruct(y_test_wm[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# remove the nan values\n",
    "y_all_pred_ev = y_all_pred_ev[~np.isnan(y_all_pred_ev)]\n",
    "y_all_true_ev = y_all_true_ev[~np.isnan(y_all_true_ev)]\n",
    "x_all_ev = x_all_ev[~np.isnan(x_all_ev)]\n",
    "# sum of nan values in the array\n",
    "np.isnan(y_all_pred_ev).sum(), np.isnan(y_all_true_ev).sum(), np.isnan(x_all_ev).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total_ev, y_total_pred_ev, y_total_true_ev = post_process.post_process_vae(x_all_ev, y_all_pred_ev, y_all_true_ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a dataframe with the true and predicted values\n",
    "import pandas as pd\n",
    "output_data = pd.DataFrame({\n",
    "    'y_total_pred': y_total_pred_ev[0, :],\n",
    "    'y_total_true': y_total_true_ev[0, :]\n",
    "})\n",
    "\n",
    "output_data.to_csv(\"Results/output/vae_ev_8156_withev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(y_total_true_ev[0, 100:12000], label=\"True\")\n",
    "plt.plot(y_total_pred_ev[0, 100:12000], label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true_ev[0, :], y_total_pred_ev[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without EV\n",
    "\n",
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true_wm[0, :], y_total_pred_wm[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dishwasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the full code for refrigerator1\n",
    "model_param[\"training\"][\"batch_size\"] = model_param[\"training\"][\"batch_sizes\"][2]\n",
    "model_param[\"preprocessing\"][\"width\"] = model_param[\"preprocessing\"][\"widths\"][2]\n",
    "model_param[\"preprocessing\"][\"strides\"] = model_param[\"preprocessing\"][\"strides_list\"][2]\n",
    "model_param[\"appliance\"] = model_param[\"appliances\"][2]\n",
    "\n",
    "main_mean = model_param[\"preprocessing\"][\"main_mean\"]\n",
    "main_std = model_param[\"preprocessing\"][\"main_std\"]\n",
    "\n",
    "app_mean = model_param[\"preprocessing\"][\"app_mean\"]\n",
    "app_std = model_param[\"preprocessing\"][\"app_std\"]\n",
    "\n",
    "x_train_dish, y_train_dish, x_test_dish, y_test_dish = helper.get_data_for_vae(1, 2, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dish.shape, y_train_dish.shape, x_test_dish.shape, y_test_dish.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = model_param[\"training\"][\"epoch\"]\n",
    "batch_size = model_param[\"training\"][\"batch_size\"]\n",
    "\n",
    "STEPS_PER_EPOCH = x_train_dish.shape[0]//batch_size\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "                float(model_param[\"training\"][\"lr\"]), \n",
    "                decay_steps=STEPS_PER_EPOCH*model_param[\"training\"][\"decay_steps\"],\n",
    "                decay_rate=1,\n",
    "                staircase=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(lr_schedule)\n",
    "\n",
    "model_dish = create_model(model_param[\"model\"], model_param[\"config\"], model_param[\"preprocessing\"][\"width\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_callbacks = []\n",
    "patience = model_param[\"training\"][\"patience\"]\n",
    "start_epoch = model_param[\"training\"][\"start_stopping\"]\n",
    "\n",
    "print(\"Patience : {}, Start at : {}\".format(patience, start_epoch))\n",
    "\n",
    "es_callback = CustomStopper(monitor='val_loss', patience=patience, start_epoch=start_epoch, mode=\"auto\")\n",
    "\n",
    "list_callbacks.append(es_callback)\n",
    "\n",
    "history_ref = model_dish.fit((x_train_dish-main_mean)/main_std, (y_train_dish-app_mean)/app_std, validation_split=model_param[\"training\"][\"validation_split\"], shuffle=True,\n",
    "                                epochs=epochs, batch_size=batch_size, callbacks=list_callbacks, verbose=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model\n",
    "y_pred_dish = model_dish.predict((x_test_dish-main_mean)/main_std, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_ref = y_pred_ref.reshape([1, -1])\n",
    "# y_test_ref = y_test_ref.reshape([1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_all_pred_dish = reconstruct(y_pred_dish[:]*app_std+app_mean, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "x_all_dish = reconstruct(x_test_dish[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "y_all_true_dish = reconstruct(y_test_dish[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# remove the nan values\n",
    "y_all_pred_dish = y_all_pred_dish[~np.isnan(y_all_pred_dish)]\n",
    "y_all_true_dish = y_all_true_dish[~np.isnan(y_all_true_dish)]\n",
    "x_all_dish = x_all_dish[~np.isnan(x_all_dish)]\n",
    "# sum of nan values in the array\n",
    "np.isnan(y_all_pred_dish).sum(), np.isnan(y_all_true_dish).sum(), np.isnan(x_all_dish).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_total_dish, y_total_pred_dish, y_total_true_dish = post_process.post_process_vae(x_all_dish, y_all_pred_dish, y_all_true_dish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a dataframe with the true and predicted values\n",
    "import pandas as pd\n",
    "output_data = pd.DataFrame({\n",
    "    'y_total_pred': y_total_pred_dish[0, :],\n",
    "    'y_total_true': y_total_true_dish[0, :]\n",
    "})\n",
    "\n",
    "output_data.to_csv(\"Results/output/vae_dish_8156_withoutev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(y_total_true_dish[0, :70000], label=\"True\")\n",
    "plt.plot(y_total_pred_dish[0, :70000], label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true_dish[0, :], y_total_pred_dish[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without ev\n",
    "\n",
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true_ref[0, :], y_total_pred_ref[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clotheswasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the full code for microwave1\n",
    "model_param[\"training\"][\"batch_size\"] = model_param[\"training\"][\"batch_sizes\"][3]\n",
    "model_param[\"preprocessing\"][\"width\"] = model_param[\"preprocessing\"][\"widths\"][3]\n",
    "model_param[\"preprocessing\"][\"strides\"] = model_param[\"preprocessing\"][\"strides_list\"][3]\n",
    "model_param[\"appliance\"] = model_param[\"appliances\"][3]\n",
    "\n",
    "main_mean = model_param[\"preprocessing\"][\"main_mean\"]\n",
    "main_std = model_param[\"preprocessing\"][\"main_std\"]\n",
    "\n",
    "app_mean = model_param[\"preprocessing\"][\"app_mean\"]\n",
    "app_std = model_param[\"preprocessing\"][\"app_std\"]\n",
    "\n",
    "x_train_cw, y_train_cw, x_test_cw, y_test_cw = helper.get_data_for_vae(2, 3, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set value 0 if power is less than 180\n",
    "y_train_cw[y_train_cw<180] = 0\n",
    "y_test_cw[y_test_cw<180] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = model_param[\"training\"][\"epoch\"]\n",
    "batch_size = model_param[\"training\"][\"batch_size\"]\n",
    "\n",
    "STEPS_PER_EPOCH = x_train_cw.shape[0]//batch_size\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "                float(model_param[\"training\"][\"lr\"]), \n",
    "                decay_steps=STEPS_PER_EPOCH*model_param[\"training\"][\"decay_steps\"],\n",
    "                decay_rate=1,\n",
    "                staircase=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(lr_schedule)\n",
    "\n",
    "model_cw = create_model(model_param[\"model\"], model_param[\"config\"], model_param[\"preprocessing\"][\"width\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_callbacks = []\n",
    "patience = model_param[\"training\"][\"patience\"]\n",
    "start_epoch = model_param[\"training\"][\"start_stopping\"]\n",
    "\n",
    "print(\"Patience : {}, Start at : {}\".format(patience, start_epoch))\n",
    "\n",
    "es_callback = CustomStopper(monitor='val_loss', patience=patience, start_epoch=start_epoch, mode=\"auto\")\n",
    "\n",
    "list_callbacks.append(es_callback)\n",
    "\n",
    "history_mw = model_cw.fit((x_train_cw-main_mean)/main_std, (y_train_cw-app_mean)/app_std, validation_split=model_param[\"training\"][\"validation_split\"], shuffle=True,\n",
    "                                epochs=epochs, batch_size=batch_size, callbacks=list_callbacks, verbose=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test the model\n",
    "y_pred_cw = model_cw.predict((x_test_cw-main_mean)/main_std, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_cw = y_pred_cw.reshape([1, -1])\n",
    "y_test_cw = y_test_cw.reshape([1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_all_pred_cw = reconstruct(y_pred_cw[:]*app_std+app_mean, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "x_all_cw = reconstruct(x_test_cw[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "y_all_true_cw = reconstruct(y_test_cw[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# remove the nan values\n",
    "y_all_pred_cw = y_all_pred_cw[~np.isnan(y_all_pred_cw)]\n",
    "y_all_true_cw = y_all_true_cw[~np.isnan(y_all_true_cw)]\n",
    "x_all_cw = x_all_cw[~np.isnan(x_all_cw)]\n",
    "# sum of nan values in the array\n",
    "np.isnan(y_all_pred_cw).sum(), np.isnan(y_all_true_cw).sum(), np.isnan(x_all_cw).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_total_cw, y_total_pred_cw, y_total_true_cw = post_process.post_process_vae(x_all_cw, y_all_pred_cw, y_all_true_cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total_pred_cw[y_total_pred_cw<180] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_total_true_cw[0, 500:37060], label=\"True\")\n",
    "plt.plot(y_total_pred_cw[0, 500:37060], label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a dataframe with the true and predicted values\n",
    "import pandas as pd\n",
    "output_data = pd.DataFrame({\n",
    "    'y_total_pred': y_total_pred_cw[0, :],\n",
    "    'y_total_true': y_total_true_cw[0, :]\n",
    "})\n",
    "\n",
    "output_data.to_csv(\"Results/output/vae_cloth_8156_withoutev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true_cw[0, :], y_total_pred_cw[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true_cw[0, :], y_total_pred_cw[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without ev\n",
    "\n",
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true_mw[0, :], y_total_pred_mw[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## air conditioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the full code for microwave1\n",
    "model_param[\"training\"][\"batch_size\"] = model_param[\"training\"][\"batch_sizes\"][4]\n",
    "model_param[\"preprocessing\"][\"width\"] = model_param[\"preprocessing\"][\"widths\"][4]\n",
    "model_param[\"preprocessing\"][\"strides\"] = model_param[\"preprocessing\"][\"strides_list\"][4]\n",
    "model_param[\"appliance\"] = model_param[\"appliances\"][4]\n",
    "\n",
    "main_mean = model_param[\"preprocessing\"][\"main_mean\"]\n",
    "main_std = model_param[\"preprocessing\"][\"main_std\"]\n",
    "\n",
    "app_mean = model_param[\"preprocessing\"][\"app_mean\"]\n",
    "app_std = model_param[\"preprocessing\"][\"app_std\"]\n",
    "\n",
    "x_train_air, y_train_air, x_test_air, y_test_air = helper.get_data_for_vae(3, 4, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set value 0 if power is less than 180\n",
    "y_train_air[y_train_air<180] = 0\n",
    "y_test_air[y_test_air<180] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = model_param[\"training\"][\"epoch\"]\n",
    "batch_size = model_param[\"training\"][\"batch_size\"]\n",
    "\n",
    "STEPS_PER_EPOCH = x_train_air.shape[0]//batch_size\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "                float(model_param[\"training\"][\"lr\"]), \n",
    "                decay_steps=STEPS_PER_EPOCH*model_param[\"training\"][\"decay_steps\"],\n",
    "                decay_rate=1,\n",
    "                staircase=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(lr_schedule)\n",
    "\n",
    "model_air = create_model(model_param[\"model\"], model_param[\"config\"], model_param[\"preprocessing\"][\"width\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_callbacks = []\n",
    "patience = model_param[\"training\"][\"patience\"]\n",
    "start_epoch = model_param[\"training\"][\"start_stopping\"]\n",
    "\n",
    "print(\"Patience : {}, Start at : {}\".format(patience, start_epoch))\n",
    "\n",
    "es_callback = CustomStopper(monitor='val_loss', patience=patience, start_epoch=start_epoch, mode=\"auto\")\n",
    "\n",
    "list_callbacks.append(es_callback)\n",
    "\n",
    "history_air = model_air.fit((x_train_air-main_mean)/main_std, (y_train_air-app_mean)/app_std, validation_split=model_param[\"training\"][\"validation_split\"], shuffle=True,\n",
    "                                epochs=epochs, batch_size=batch_size, callbacks=list_callbacks, verbose=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test the model\n",
    "y_pred_air = model_air.predict((x_test_air-main_mean)/main_std, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_all_pred_air = reconstruct(y_pred_air[:]*app_std+app_mean, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "x_all_air = reconstruct(x_test_air[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "y_all_true_air = reconstruct(y_test_air[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# remove the nan values\n",
    "y_all_pred_air = y_all_pred_air[~np.isnan(y_all_pred_air)]\n",
    "y_all_true_air = y_all_true_air[~np.isnan(y_all_true_air)]\n",
    "x_all_air = x_all_air[~np.isnan(x_all_air)]\n",
    "# sum of nan values in the array\n",
    "np.isnan(y_all_pred_air).sum(), np.isnan(y_all_true_air).sum(), np.isnan(x_all_air).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_total_air, y_total_pred_air, y_total_true_air = post_process.post_process_vae(x_all_air, y_all_pred_air, y_all_true_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_total_true_air[0, 500:37060], label=\"True\")\n",
    "plt.plot(y_total_pred_air[0, 500:37060], label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a dataframe with the true and predicted values\n",
    "import pandas as pd\n",
    "output_data = pd.DataFrame({\n",
    "    'y_total_pred': y_total_pred_air[0, :],\n",
    "    'y_total_true': y_total_true_air[0, :]\n",
    "})\n",
    "\n",
    "output_data.to_csv(\"Results/output/vae_air_8156_withoutev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true_air[0, :], y_total_pred_air[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the full code for microwave1\n",
    "model_param[\"training\"][\"batch_size\"] = model_param[\"training\"][\"batch_sizes\"][5]\n",
    "model_param[\"preprocessing\"][\"width\"] = model_param[\"preprocessing\"][\"widths\"][5]\n",
    "model_param[\"preprocessing\"][\"strides\"] = model_param[\"preprocessing\"][\"strides_list\"][5]\n",
    "model_param[\"appliance\"] = model_param[\"appliances\"][5]\n",
    "\n",
    "main_mean = model_param[\"preprocessing\"][\"main_mean\"]\n",
    "main_std = model_param[\"preprocessing\"][\"main_std\"]\n",
    "\n",
    "app_mean = model_param[\"preprocessing\"][\"app_mean\"]\n",
    "app_std = model_param[\"preprocessing\"][\"app_std\"]\n",
    "\n",
    "x_train_mic, y_train_mic, x_test_mic, y_test_mic = helper.get_data_for_vae(4, 5, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = model_param[\"training\"][\"epoch\"]\n",
    "batch_size = model_param[\"training\"][\"batch_size\"]\n",
    "\n",
    "STEPS_PER_EPOCH = x_train_mic.shape[0]//batch_size\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "                float(model_param[\"training\"][\"lr\"]), \n",
    "                decay_steps=STEPS_PER_EPOCH*model_param[\"training\"][\"decay_steps\"],\n",
    "                decay_rate=1,\n",
    "                staircase=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(lr_schedule)\n",
    "\n",
    "model_mic = create_model(model_param[\"model\"], model_param[\"config\"], model_param[\"preprocessing\"][\"width\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_callbacks = []\n",
    "patience = model_param[\"training\"][\"patience\"]\n",
    "start_epoch = model_param[\"training\"][\"start_stopping\"]\n",
    "\n",
    "print(\"Patience : {}, Start at : {}\".format(patience, start_epoch))\n",
    "\n",
    "es_callback = CustomStopper(monitor='val_loss', patience=patience, start_epoch=start_epoch, mode=\"auto\")\n",
    "\n",
    "list_callbacks.append(es_callback)\n",
    "\n",
    "history_mic = model_mic.fit((x_train_mic-main_mean)/main_std, (y_train_mic-app_mean)/app_std, validation_split=model_param[\"training\"][\"validation_split\"], shuffle=True,\n",
    "                                epochs=epochs, batch_size=batch_size, callbacks=list_callbacks, verbose=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test the model\n",
    "y_pred_mic = model_mic.predict((x_test_mic-main_mean)/main_std, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_all_pred_mic = reconstruct(y_pred_mic[:]*app_std+app_mean, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "x_all_mic = reconstruct(x_test_mic[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "y_all_true_mic = reconstruct(y_test_mic[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# remove the nan values\n",
    "y_all_pred_mic = y_all_pred_mic[~np.isnan(y_all_pred_mic)]\n",
    "y_all_true_mic = y_all_true_mic[~np.isnan(y_all_true_mic)]\n",
    "x_all_mic = x_all_mic[~np.isnan(x_all_mic)]\n",
    "# sum of nan values in the array\n",
    "np.isnan(y_all_pred_mic).sum(), np.isnan(y_all_true_mic).sum(), np.isnan(x_all_mic).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_total_mic, y_total_pred_mic, y_total_true_mic = post_process.post_process_vae(x_all_mic, y_all_pred_mic, y_all_true_mic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_total_true_mic[0, 500:37060], label=\"True\")\n",
    "plt.plot(y_total_pred_mic[0, 500:37060], label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a dataframe with the true and predicted values\n",
    "import pandas as pd\n",
    "output_data = pd.DataFrame({\n",
    "    'y_total_pred': y_total_pred_mic[0, :],\n",
    "    'y_total_true': y_total_true_mic[0, :]\n",
    "})\n",
    "\n",
    "output_data.to_csv(\"Results/output/vae_mic_8156_withoutev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true_mic[0, :], y_total_pred_mic[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## others(White appliances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the full code for others\n",
    "model_param[\"training\"][\"batch_size\"] = model_param[\"training\"][\"batch_sizes\"][6]\n",
    "model_param[\"preprocessing\"][\"width\"] = model_param[\"preprocessing\"][\"widths\"][6]\n",
    "model_param[\"preprocessing\"][\"strides\"] = model_param[\"preprocessing\"][\"strides_list\"][6]\n",
    "model_param[\"appliance\"] = model_param[\"appliances\"][6]\n",
    "main_mean = model_param[\"preprocessing\"][\"main_mean\"]\n",
    "main_std = model_param[\"preprocessing\"][\"main_std\"]\n",
    "app_mean = model_param[\"preprocessing\"][\"app_mean\"]\n",
    "app_std = model_param[\"preprocessing\"][\"app_std\"]\n",
    "x_train_others, y_train_others, x_test_others, y_test_others = helper.get_data_for_vae(5, 6, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = model_param[\"training\"][\"epoch\"]\n",
    "batch_size = model_param[\"training\"][\"batch_size\"]\n",
    "STEPS_PER_EPOCH = x_train_others.shape[0]//batch_size\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "                float(model_param[\"training\"][\"lr\"]), \n",
    "                decay_steps=STEPS_PER_EPOCH*model_param[\"training\"][\"decay_steps\"],\n",
    "                decay_rate=1,\n",
    "                staircase=False)\n",
    "optimizer = tf.keras.optimizers.RMSprop(lr_schedule)\n",
    "model_others = create_model(model_param[\"model\"], model_param[\"config\"], model_param[\"preprocessing\"][\"width\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continue\n",
    "list_callbacks = []\n",
    "patience = model_param[\"training\"][\"patience\"]\n",
    "start_epoch = model_param[\"training\"][\"start_stopping\"]\n",
    "print(\"Patience : {}, Start at : {}\".format(patience, start_epoch))\n",
    "es_callback = CustomStopper(monitor='val_loss', patience=patience, start_epoch=start_epoch, mode=\"auto\")\n",
    "list_callbacks.append(es_callback)\n",
    "history_others = model_others.fit((x_train_others-main_mean)/main_std, (y_train_others-app_mean)/app_std, validation_split=model_param[\"training\"][\"validation_split\"], shuffle=True,\n",
    "                                epochs=epochs, batch_size=batch_size, callbacks=list_callbacks, verbose=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue\n",
    "y_pred_others = model_others.predict((x_test_others-main_mean)/main_std, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continue\n",
    "\n",
    "y_all_pred_others = reconstruct(y_pred_others[:]*app_std+app_mean, model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "x_all_others = reconstruct(x_test_others[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")\n",
    "y_all_true_others = reconstruct(y_test_others[:], model_param[\"preprocessing\"][\"width\"], model_param[\"preprocessing\"][\"strides\"], \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# remove the nan values\n",
    "y_all_pred_others = y_all_pred_others[~np.isnan(y_all_pred_others)]\n",
    "y_all_true_others = y_all_true_others[~np.isnan(y_all_true_others)]\n",
    "x_all_others = x_all_others[~np.isnan(x_all_others)]\n",
    "# sum of nan values in the array\n",
    "np.isnan(y_all_pred_others).sum(), np.isnan(y_all_true_others).sum(), np.isnan(x_all_others).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total_others, y_total_pred_others, y_total_true_others = post_process.post_process_vae(x_all_others, y_all_pred_others, y_all_true_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_total_true_others[0, 500:37060], label=\"True\")\n",
    "plt.plot(y_total_pred_others[0, 500:37060], label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare a dataframe with the true and predicted values\n",
    "import pandas as pd\n",
    "output_data = pd.DataFrame({\n",
    "    'y_total_pred': y_total_pred_others[0, :],\n",
    "    'y_total_true': y_total_true_others[0, :]\n",
    "})\n",
    "output_data.to_csv(\"Results/output/vae_others_8156_withoutev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true_others[0, :], y_total_pred_others[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(y_total_true_others[0, :], y_total_pred_others[0, :])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
