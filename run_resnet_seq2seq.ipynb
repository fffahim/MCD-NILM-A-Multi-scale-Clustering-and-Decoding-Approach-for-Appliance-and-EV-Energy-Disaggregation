{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchinfo import summary\n",
    "\n",
    "%run data_preprocess.ipynb\n",
    "%run helper.ipynb\n",
    "%run wrapper.ipynb\n",
    "%run models/ResNet_seq2seq.ipynb\n",
    "%run visualize.ipynb\n",
    "%run data_postprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataport_appliance_data_661 = {\n",
    "    \"refrigerator\": {\n",
    "        \"mean\": 60.52,\n",
    "        \"std\": 66.42,\n",
    "        \"window\":100,\n",
    "        'on_power_threshold': 50,\n",
    "        'min': 0,\n",
    "        'max': 683\n",
    "    },\n",
    "    \"ev_car\": {\n",
    "        \"mean\": 204.14,\n",
    "        \"std\": 737,\n",
    "        'window':10,\n",
    "        'on_power_threshold': 2000,\n",
    "        'max': 3420,\n",
    "        'min': 0,\n",
    "    },\n",
    "    \"dishwasher\": {\n",
    "        \"mean\": 6.77,\n",
    "        \"std\": 55.07,\n",
    "        \"window\":3,\n",
    "        'on_power_threshold': 10,\n",
    "        'max': 960,\n",
    "        'min': 0,\n",
    "    },\n",
    "    \"clotheswasher\": {\n",
    "        \"mean\": 7.38,\n",
    "        \"std\": 52.77,\n",
    "        \"window\":100,\n",
    "        'on_power_threshold': 20,\n",
    "        'max': 1143,\n",
    "        'min': 0,\n",
    "    },\n",
    "    \"air\": {\n",
    "        \"mean\": 442.99,\n",
    "        \"std\": 769.72,\n",
    "        \"window\":100,\n",
    "        'on_power_threshold': 20,\n",
    "        'max': 2783,\n",
    "        'min': 0,\n",
    "    },\n",
    "    \"microwave\": {\n",
    "        \"mean\": 8.23,\n",
    "        \"std\": 36.44,\n",
    "        \"window\":100,\n",
    "        'on_power_threshold': 200,\n",
    "        'min': 0,\n",
    "        'max': 980\n",
    "    },\n",
    "    \"others\": {\n",
    "        \"mean\": 195,\n",
    "        \"std\": 178,\n",
    "        \"window\":100,\n",
    "        'on_power_threshold': 0,\n",
    "        'min': 0,\n",
    "        'max': 1942\n",
    "    }\n",
    "}\n",
    "\n",
    "# 8156\n",
    "dataport_appliance_data_8156 = {\n",
    "    \"refrigerator\": {\n",
    "        \"mean\": 93.80,\n",
    "        \"std\": 54.22,\n",
    "        \"window\":100,\n",
    "        'on_power_threshold': 50,\n",
    "        'min': 6,\n",
    "        'max': 562\n",
    "    },\n",
    "    \"ev_car\": {\n",
    "        \"mean\": 207.76,\n",
    "        \"std\": 750.25,\n",
    "        'window':10,\n",
    "        'on_power_threshold': 2000,\n",
    "        'max': 3330,\n",
    "        'min': 0,\n",
    "    },\n",
    "    \"dishwasher\": {\n",
    "        \"mean\": 28.34,\n",
    "        \"std\": 117.14,\n",
    "        \"window\":3,\n",
    "        'on_power_threshold': 10,\n",
    "        'max': 936,\n",
    "        'min': 0,\n",
    "    },\n",
    "    \"clotheswasher\": {\n",
    "        \"mean\": 16.72,\n",
    "        \"std\": 96.89,\n",
    "        \"window\":100,\n",
    "        'on_power_threshold': 20,\n",
    "        'max': 1141,\n",
    "        'min': 0,\n",
    "    },\n",
    "    \"air\": {\n",
    "        \"mean\": 918.16,\n",
    "        \"std\": 1214.59,\n",
    "        \"window\":100,\n",
    "        'on_power_threshold': 20,\n",
    "        'max': 3949,\n",
    "        'min': 0,\n",
    "    },\n",
    "    \"microwave\": {\n",
    "        \"mean\": 13.89,\n",
    "        \"std\": 73.69,\n",
    "        \"window\":100,\n",
    "        'on_power_threshold': 200,\n",
    "        'min': 0,\n",
    "        'max': 1678\n",
    "    },\n",
    "    \"others\": {\n",
    "        \"mean\": 610.91,\n",
    "        \"std\": 461.16,\n",
    "        \"window\":100,\n",
    "        'on_power_threshold': 0,\n",
    "        'min': 76,\n",
    "        'max': 5226\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Config/model_config.json\") as json_data:\n",
    "    data = json.load(json_data, object_hook=lambda d: SimpleNamespace(**d))\n",
    "    model_params = data.resnet_seq2seq\n",
    "    model_params.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = Visualizer()\n",
    "data_postprocess = DataPostProcess(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = PrepareDataForQuantile(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = Wrapper(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = ModelEvaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create another json with the ev car only\n",
    "dataport_appliance_data_ev = {\n",
    "    \"ev_car\": dataport_appliance_data_8156[\"ev_car\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataport_appliance_data_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_ev, test_loader_ev, val_loader_ev = helper.get_data_loaders(1, 2, model_params.lag_sizes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader_ev:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params.lag_size = model_params.lag_sizes[0]\n",
    "model_ev = ResNetSeq2Seq(model_params).to(model_params.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model_ev.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_ev, prediction_ev = wrapper.regression_model_train(model_ev, train_loader_ev, val_loader_ev, optimizer, criterion, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_plot( ground_truth_ev.cpu().detach().numpy(), prediction_ev.cpu().detach().numpy(), 00, 186000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test_ev, prediction_test_ev = wrapper.regression_model_test(model_ev, test_loader_ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create another json with the ev car only\n",
    "dataport_appliance_data_ev_test = {\n",
    "    \"ev_car\": dataport_appliance_data_661[\"ev_car\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_ev_scaled, prediction_ev_scaled = data_postprocess.reverse_scale_data_unetnilm(ground_truth_test_ev.cpu().detach().numpy(), prediction_test_ev.cpu().detach().numpy(), dataport_appliance_data_ev_test, 'standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_ev_scaled = ground_truth_test_ev.cpu().detach().numpy()\n",
    "prediction_ev_scaled = prediction_test_ev.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_plot( ground_truth_ev_scaled, prediction_ev_scaled, 00, 180000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(ground_truth_ev_scaled[:, 0], prediction_ev_scaled[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({\n",
    "   \"ground_truth\": ground_truth_ev_scaled[:, 0],\n",
    "   \"prediction\": prediction_ev_scaled[:, 0]\n",
    "})\n",
    "\n",
    "dataframe.to_csv(\"Results/output/resnet_8156_seq2seq_ev_withev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Washing machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the whole code for the washing maching\n",
    "dataport_appliance_data_wm = {\n",
    "    \"clotheswasher\": dataport_appliance_data_8156[\"clotheswasher\"]\n",
    "}\n",
    "\n",
    "train_loader_wm, test_loader_wm, val_loader_wm = helper.get_data_loaders(3, 4, model_params.lag_sizes[1])\n",
    "\n",
    "for x, y in train_loader_wm:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "model_params.lag_size = model_params.lag_sizes[1]\n",
    "\n",
    "model_wm = ResNetSeq2Seq(model_params).to(model_params.device)\n",
    "\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model_wm.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "summary(model_wm, input_size=x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_wm, prediction_wm = wrapper.regression_model_train(model_wm, train_loader_wm, val_loader_wm, optimizer, criterion, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_plot( ground_truth_wm.cpu().detach().numpy(), prediction_wm.cpu().detach().numpy(), 0, 7000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test_wm, prediction_test_wm = wrapper.regression_model_test(model_wm, test_loader_wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_wm_scaled, prediction_wm_scaled = data_postprocess.reverse_scale_data_unetnilm(ground_truth_test_wm.cpu().detach().numpy(), prediction_test_wm.cpu().detach().numpy(), dataport_appliance_data_wm, 'standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_wm_scaled = ground_truth_test_wm.cpu().detach().numpy()\n",
    "prediction_wm_scaled = prediction_test_wm.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_plot( ground_truth_wm_scaled, prediction_wm_scaled, 00, 180000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(ground_truth_wm_scaled[:, 0], prediction_wm_scaled[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame({\n",
    "   \"ground_truth\": ground_truth_wm_scaled[:, 0],\n",
    "    \"prediction\": prediction_wm_scaled[:, 0]\n",
    "})\n",
    "\n",
    "data_frame.to_csv(\"Results/output/resnet_8156_seq2seq_wm_withev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrigerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##write the whole code for the refrigerator\n",
    "dataport_appliance_data_ref = {\n",
    "    \"refrigerator\": dataport_appliance_data[\"refrigerator\"]\n",
    "}\n",
    "\n",
    "train_loader_ref, test_loader_ref, val_loader_ref = helper.get_data_loaders(0, 1, model_params.lag_sizes[2])\n",
    "\n",
    "for x, y in train_loader_ref:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "model_params.lag_size = model_params.lag_sizes[2]\n",
    "\n",
    "model_ref = ResNetSeq2Seq(model_params).to(model_params.device)\n",
    "\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model_ref.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "ground_truth_ref, prediction_ref = wrapper.regression_model_train(model_ref, train_loader_ref, val_loader_ref, optimizer, criterion, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_plot( ground_truth_ref.cpu().detach().numpy(), prediction_ref.cpu().detach().numpy(), 0, 7000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test_ref, prediction_test_ref = wrapper.regression_model_test(model_ref, test_loader_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_ref_scaled, prediction_ref_scaled = data_postprocess.reverse_scale_data_unetnilm(ground_truth_test_ref.cpu().detach().numpy(), prediction_test_ref.cpu().detach().numpy(), dataport_appliance_data_ref, 'standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualizer.visualize_plot( ground_truth_ref_scaled, prediction_ref_scaled, 00, 500000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative values to zero\n",
    "prediction_ref_scaled[prediction_ref_scaled < 0] = 0\n",
    "ground_truth_ref_scaled[ground_truth_ref_scaled < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(ground_truth_ref_scaled[:, 0], prediction_ref_scaled[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({\n",
    "   \"ground_truth\": ground_truth_ref_scaled[:, 0],\n",
    "    \"prediction\": prediction_ref_scaled[:, 0]\n",
    "})\n",
    "\n",
    "dataframe.to_csv(\"Results/output/resnet_8156_seq2seq_ref_withev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write the whole code for the microwave\n",
    "dataport_appliance_data_mw = {\n",
    "    \"microwave\": dataport_appliance_data[\"microwave\"]\n",
    "}\n",
    "\n",
    "train_loader_mw, test_loader_mw, val_loader_mw = helper.get_data_loaders(2, 3, model_params.lag_sizes[3])\n",
    "\n",
    "for x, y in train_loader_mw:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "model_params.lag_size = model_params.lag_sizes[3]\n",
    "\n",
    "model_mw = ResNetSeq2Seq(model_params).to(model_params.device)\n",
    "\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model_mw.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "ground_truth_mw, prediction_mw = wrapper.regression_model_train(model_mw, train_loader_mw, val_loader_mw, optimizer, criterion, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualizer.visualize_plot( ground_truth_mw.cpu().detach().numpy(), prediction_mw.cpu().detach().numpy(), 0, 7000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test_mw, prediction_test_mw = wrapper.regression_model_test(model_mw, test_loader_mw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_mw_scaled, prediction_mw_scaled = data_postprocess.reverse_scale_data_unetnilm(ground_truth_test_mw.cpu().detach().numpy(), prediction_test_mw.cpu().detach().numpy(), dataport_appliance_data_mw, 'standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_plot( ground_truth_mw_scaled, prediction_mw_scaled, 00, 18000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(ground_truth_mw_scaled[:, 0], prediction_mw_scaled[:, 0])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(ground_truth_mw_scaled[:, 0], prediction_mw_scaled[:, 0])\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mx = pd.DataFrame({\n",
    "   \"ground_truth\": ground_truth_mw_scaled[:, 0],\n",
    "    \"prediction\": prediction_mw_scaled[:, 0]\n",
    "})\n",
    "dataframe_mx.to_csv(\"Results/output/resnet_8156_seq2seq_mw_withoutv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## air\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write the whole code for the air conditioner\n",
    "dataport_appliance_data_air = {\n",
    "    \"air\": dataport_appliance_data[\"air\"]\n",
    "}\n",
    "train_loader_air, test_loader_air, val_loader_air = helper.get_data_loaders(3, 4, model_params.lag_sizes[4])\n",
    "for x, y in train_loader_air:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "model_params.lag_size = model_params.lag_sizes[4]\n",
    "model_air = ResNetSeq2Seq(model_params).to(model_params.device)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model_air.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "ground_truth_air, prediction_air = wrapper.regression_model_train(model_air, train_loader_air, val_loader_air, optimizer, criterion, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_plot( ground_truth_air.cpu().detach().numpy(), prediction_air.cpu().detach().numpy(), 0, 7000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test_air, prediction_test_air = wrapper.regression_model_test(model_air, test_loader_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_air_scaled, prediction_air_scaled = data_postprocess.reverse_scale_data_unetnilm(ground_truth_test_air.cpu().detach().numpy(), prediction_test_air.cpu().detach().numpy(), dataport_appliance_data_air, 'standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_plot( ground_truth_air_scaled, prediction_air_scaled, 00, 180000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(ground_truth_air_scaled[:, 0], prediction_air_scaled[:, 0])\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({\n",
    "   \"ground_truth\": ground_truth_air_scaled[:, 0],\n",
    "    \"prediction\": prediction_air_scaled[:, 0]\n",
    "})\n",
    "dataframe.to_csv(\"Results/output/resnet_8156_seq2seq_air_withoutev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dishwasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the whole code for the dishwasher\n",
    "dataport_appliance_data_dishwasher = {\n",
    "    \"dishwasher\": dataport_appliance_data[\"dishwasher\"]\n",
    "}\n",
    "\n",
    "train_loader_dishwasher, test_loader_dishwasher, val_loader_dishwasher = helper.get_data_loaders(1, 2, model_params.lag_sizes[5])\n",
    "for x, y in train_loader_dishwasher:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "model_params.lag_size = model_params.lag_sizes[5]\n",
    "model_dishwasher = ResNetSeq2Seq(model_params).to(model_params.device)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model_dishwasher.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "ground_truth_dishwasher, prediction_dishwasher = wrapper.regression_model_train(model_dishwasher, train_loader_dishwasher, val_loader_dishwasher, optimizer, criterion, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualizer.visualize_plot( ground_truth_dishwasher.cpu().detach().numpy(), prediction_dishwasher.cpu().detach().numpy(), 0, 7000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ground_truth_test_dishwasher, prediction_test_dishwasher = wrapper.regression_model_test(model_dishwasher, test_loader_dishwasher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dishwasher_scaled, prediction_dishwasher_scaled = data_postprocess.reverse_scale_data_unetnilm(ground_truth_test_dishwasher.cpu().detach().numpy(), prediction_test_dishwasher.cpu().detach().numpy(), dataport_appliance_data_dishwasher, 'standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_plot( ground_truth_dishwasher_scaled, prediction_dishwasher_scaled, 00, 180000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(ground_truth_dishwasher_scaled[:, 0], prediction_dishwasher_scaled[:, 0])\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dishwasher = pd.DataFrame({\n",
    "   \"ground_truth\": ground_truth_dishwasher_scaled[:, 0],\n",
    "    \"prediction\": prediction_dishwasher_scaled[:, 0]\n",
    "})\n",
    "dataframe_dishwasher.to_csv(\"Results/output/resnet_8156_seq2seq_dishwasher_withoutev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the whole code for the others\n",
    "dataport_appliance_data_others = {\n",
    "    \"others\": dataport_appliance_data[\"others\"]\n",
    "}\n",
    "\n",
    "train_loader_others, test_loader_others, val_loader_others = helper.get_data_loaders(5, 6, model_params.lag_sizes[6])\n",
    "for x, y in train_loader_others:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "model_params.lag_size = model_params.lag_sizes[6]\n",
    "model_others = ResNetSeq2Seq(model_params).to(model_params.device)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model_others.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "ground_truth_others, prediction_others = wrapper.regression_model_train(model_others, train_loader_others, val_loader_others, optimizer, criterion, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualizer.visualize_plot( ground_truth_others.cpu().detach().numpy(), prediction_others.cpu().detach().numpy(), 0, 7000, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test_others, prediction_test_others = wrapper.regression_model_test(model_others, test_loader_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_others_scaled, prediction_others_scaled = data_postprocess.reverse_scale_data_unetnilm(ground_truth_test_others.cpu().detach().numpy(), prediction_test_others.cpu().detach().numpy(), dataport_appliance_data_others, 'standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_plot( ground_truth_others_scaled, prediction_others_scaled, 00, 180000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, eac, nde = wrapper.evaluation_metrics(ground_truth_others_scaled[:, 0], prediction_others_scaled[:, 0])\n",
    "print(\"MAE: \", mae)\n",
    "print(\"EAC: \", eac)\n",
    "print(\"NDE: \", nde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_others = pd.DataFrame({\n",
    "   \"ground_truth\": ground_truth_others_scaled[:, 0],\n",
    "    \"prediction\": prediction_others_scaled[:, 0]\n",
    "})\n",
    "dataframe_others.to_csv(\"Results/output/resnet_8156_seq2seq_others_withev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
